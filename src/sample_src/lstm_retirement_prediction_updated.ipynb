{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# LSTM \uc740\ud1f4\uc5f0\ub3c4 \uc608\uce21 \ubaa8\ub378 (\uac1c\uc120\ub41c \ubc84\uc804)\n\n\uc774 \ub178\ud2b8\ubd81\uc740 \uc120\uc218\uc758 \ub9c8\uc9c0\ub9c9 N\uc2dc\uc98c \ub370\uc774\ud130\ub97c \uae30\ubc18\uc73c\ub85c \uc740\ud1f4 \uc5f0\ub3c4\ub97c \uc608\uce21\ud569\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Colab \ud658\uacbd\uc5d0\uc11c\ub294 \ud544\uc694 \uc2dc \uc544\ub798 \uba85\ub839\uc5b4 \uc2e4\ud589\n", "# !pip install torch pandas scikit-learn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "from torch.utils.data import Dataset, DataLoader\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.preprocessing import MinMaxScaler\n", "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# CSV \ud30c\uc77c \uc5c5\ub85c\ub4dc (Colab \ud658\uacbd)\n", "# from google.colab import files\n", "# uploaded = files.upload()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ub370\uc774\ud130 \ub85c\ub529 \ubc0f \uc804\ucc98\ub9ac\n", "df = pd.read_csv('kbo_retired.csv')  # Colab\uc740 \uc5c5\ub85c\ub4dc \ud6c4 \ud30c\uc77c\uba85 \ud655\uc778\n", "features = ['AVG', 'SLG', 'OBP', 'G', 'AB', 'R', 'H', 'HR', 'RBI']\n", "df[features] = df[features].replace('-', np.nan)\n", "df = df.dropna(subset=features + ['season', 'name'])\n", "df['player_id'] = df['name']\n", "df = df.sort_values(['player_id', 'season'])\n", "df[features] = MinMaxScaler().fit_transform(df[features])\n", "# \uc740\ud1f4 \uc5f0\ub3c4 \ucd94\uac00\n", "df['retire_season'] = df.groupby('player_id')['season'].transform('max')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \uc2dc\ud000\uc2a4 \uc0dd\uc131 (\ub9c8\uc9c0\ub9c9 N\uc2dc\uc98c \uae30\ubc18)\n", "sequence_length = 5\n", "sequences, targets = [], []\n", "for player, group in df.groupby('player_id'):\n", "    if len(group) < sequence_length:\n", "        continue\n", "    group = group.sort_values('season')\n", "    seq = group.iloc[-sequence_length:][features].values\n", "    target = group.iloc[-1]['retire_season']\n", "    sequences.append(seq)\n", "    targets.append(target)\n", "X = np.array(sequences, dtype=np.float32)\n", "y = np.array(targets, dtype=np.float32)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud559\uc2b5/\uac80\uc99d \ubd84\ud560 \ubc0f Dataset \uc815\uc758\n", "from torch.utils.data import Dataset, DataLoader\n", "class PlayerDataset(Dataset):\n", "    def __init__(self, X, y):\n", "        self.X = torch.tensor(X)\n", "        self.y = torch.tensor(y).unsqueeze(1)\n", "    def __len__(self):\n", "        return len(self.X)\n", "    def __getitem__(self, idx):\n", "        return self.X[idx], self.y[idx]\n", "\n", "split_idx = int(len(X) * 0.8)\n", "train_ds = PlayerDataset(X[:split_idx], y[:split_idx])\n", "test_ds = PlayerDataset(X[split_idx:], y[split_idx:])\n", "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n", "test_loader = DataLoader(test_ds, batch_size=32)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# LSTM \ubaa8\ub378 \uc815\uc758\n", "class LSTMModel(nn.Module):\n", "    def __init__(self, input_size, hidden_size=32, num_layers=1):\n", "        super().__init__()\n", "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n", "        self.fc = nn.Linear(hidden_size, 1)\n", "    def forward(self, x):\n", "        _, (h_n, _) = self.lstm(x)\n", "        return self.fc(h_n[-1])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ubaa8\ub378 \ud559\uc2b5\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "model = LSTMModel(input_size=X.shape[2]).to(device)\n", "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n", "criterion = nn.MSELoss()\n", "\n", "for epoch in range(20):\n", "    model.train()\n", "    total_loss = 0\n", "    for xb, yb in train_loader:\n", "        xb, yb = xb.to(device), yb.to(device)\n", "        pred = model(xb)\n", "        loss = criterion(pred, yb)\n", "        optimizer.zero_grad()\n", "        loss.backward()\n", "        optimizer.step()\n", "        total_loss += loss.item()\n", "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \uc608\uce21 \ubc0f \ud3c9\uac00\uc9c0\ud45c\n", "model.eval()\n", "preds, actuals = [], []\n", "with torch.no_grad():\n", "    for xb, yb in test_loader:\n", "        xb = xb.to(device)\n", "        pred = model(xb).cpu().numpy()\n", "        preds.append(pred)\n", "        actuals.append(yb.numpy())\n", "\n", "preds = np.vstack(preds).flatten()\n", "actuals = np.vstack(actuals).flatten()\n", "\n", "mse = mean_squared_error(actuals, preds)\n", "mae = mean_absolute_error(actuals, preds)\n", "r2 = r2_score(actuals, preds)\n", "print({\"MSE\": mse, \"MAE\": mae, \"R2\": r2})"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 2}